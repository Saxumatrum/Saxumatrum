{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saxumatrum/Saxumatrum/blob/main/aam71.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIg6enKVhhi4"
      },
      "source": [
        "\n",
        "\n",
        "## **COMP6685 Deep Learning Coursework A1**\n",
        "\n",
        "\n",
        "Individual (25% of total mark)\n",
        "\n",
        "\n",
        "**TASK:**\tYou are required to develop a phyton code with appropriate comments and answer questions.\n",
        "\n",
        "**Description**: Create a code using this temlate to train a Convolutional Neural Network (CNN) on the fashion MNIST dataset available at https://keras.io/api/datasets/fashion_mnist/ . \n",
        "\n",
        "Fashion MNIST is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images.\n",
        "\n",
        "The dataset should be imported in the code and one sample image should be visualised before applying the model.\n",
        "\n",
        "Define a CNN and comment the chosen parameters of the network. Apply a regularization method (L1, L2 or L1L2). Divide the dataset into training, validation and test set. Obtain the accuracy on the validation set and plot the final results using the data from the test set. Comment your lines of code appropriately to explain your solution.\n",
        "\n",
        "Enhance the model's performance to obtain the best or optimal validation accuracy. Further questions about final remarks on the results will be answered on the markdown defined in the template.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "Note: This is only a template. You can add more code/text cells if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qysRQbvOm1c4"
      },
      "source": [
        "Import the dataset and divide it appropriately into sets for cross-validation. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tV9PO1GBl5_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6037cdc4-dc18-4230-f013-8742084a0fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Ready\n"
          ]
        }
      ],
      "source": [
        "#Importing of libraries\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras import utils\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#import and split fashion mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# consider them as float and normalize\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "\n",
        "#show the size of the train and test datasets\n",
        "print(train_images.shape[0], 'train samples')\n",
        "print(test_images.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Ready')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ-3DSkDdrUh"
      },
      "source": [
        "*your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-xHphsvmG7F"
      },
      "source": [
        "Visualise a random sample image of the dataset. **(5 marks)**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bTTrIN_nnDWK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "75072465-1c1a-4b89-f4fc-648716a1e632"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import random\n",
        "number=np.random.randint(len(train_images))\n",
        "image=train_images[number]\n",
        "plt.imshow(image.reshape(28,28))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMhGFcimoUwz"
      },
      "source": [
        "Define your CNN model. Specify the network and training parameters and comment them. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "urupEGOFooUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca97c38b-0d69-4309-a4cd-3c0a899d0396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               627300    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 629,142\n",
            "Trainable params: 629,142\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#TRAINING PARAMETERS\n",
        "\n",
        "BATCH_SIZE=128\n",
        "N_EPOCHS=10\n",
        "VALIDATION_SPLIT=0.2\n",
        "VERBOSE=1\n",
        "INPUTS=(28,28,1)\n",
        "N_CLASSES=10\n",
        "\n",
        "#DEFINING THE CNN\n",
        "\n",
        "inputs=keras.Input(shape=INPUTS)\n",
        "\n",
        "#first input layer with L1 regularisation and first pooling layer\n",
        "first=layers.Conv2D(filters=32, kernel_size=5,activation='relu',kernel_regularizer=regularizers.l1(0.001),padding='same')(inputs)\n",
        "first_pool=layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same')(first)\n",
        "\n",
        "\n",
        "#flatten output from pooling into linear vector\n",
        "flat=layers.Flatten()(first_pool)\n",
        "\n",
        "#dense layer with 100 neurons and a drpout of 0.5\n",
        "third=layers.Dense(100,activation='relu')(flat)\n",
        "dropout=layers.Dropout(0.5)(third)\n",
        "\n",
        "#output layer with 10 neurons and softmax activation\n",
        "fourth=layers.Dense(N_CLASSES,activation='softmax')(dropout)\n",
        "\n",
        "\n",
        "\n",
        "#declaring the model\n",
        "model = keras.Model(inputs=inputs, outputs=fourth)\n",
        "\n",
        "\n",
        "#compiling the model with parameters\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csCYqn-9pDuJ"
      },
      "source": [
        "Train the CNN model using k-fold cross-validation. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xESPeCWnpJek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1292a79c-8005-4499-b539-4c2d21a54201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-FOLD 1\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 50s 129ms/step - loss: 0.6416 - accuracy: 0.7914 - val_loss: 0.4133 - val_accuracy: 0.8645\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.4415 - accuracy: 0.8617 - val_loss: 0.3608 - val_accuracy: 0.8842\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 38s 103ms/step - loss: 0.3908 - accuracy: 0.8773 - val_loss: 0.3315 - val_accuracy: 0.8916\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.3590 - accuracy: 0.8865 - val_loss: 0.3132 - val_accuracy: 0.8990\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.3405 - accuracy: 0.8921 - val_loss: 0.3022 - val_accuracy: 0.9037\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 40s 106ms/step - loss: 0.3248 - accuracy: 0.8961 - val_loss: 0.2966 - val_accuracy: 0.9038\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.3125 - accuracy: 0.8999 - val_loss: 0.2922 - val_accuracy: 0.9052\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.2992 - accuracy: 0.9045 - val_loss: 0.3032 - val_accuracy: 0.8979\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.2878 - accuracy: 0.9081 - val_loss: 0.2828 - val_accuracy: 0.9090\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.2795 - accuracy: 0.9099 - val_loss: 0.2745 - val_accuracy: 0.9086\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2879 - accuracy: 0.9054\n",
            "K-FOLD 2\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.2698 - accuracy: 0.9140 - val_loss: 0.2781 - val_accuracy: 0.9095\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.2638 - accuracy: 0.9165 - val_loss: 0.2752 - val_accuracy: 0.9131\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.2558 - accuracy: 0.9179 - val_loss: 0.2752 - val_accuracy: 0.9120\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.2522 - accuracy: 0.9200 - val_loss: 0.2672 - val_accuracy: 0.9151\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 38s 103ms/step - loss: 0.2470 - accuracy: 0.9205 - val_loss: 0.2799 - val_accuracy: 0.9090\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.2405 - accuracy: 0.9237 - val_loss: 0.2730 - val_accuracy: 0.9133\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.2317 - accuracy: 0.9260 - val_loss: 0.2797 - val_accuracy: 0.9112\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.2271 - accuracy: 0.9267 - val_loss: 0.2732 - val_accuracy: 0.9113\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.2224 - accuracy: 0.9294 - val_loss: 0.2678 - val_accuracy: 0.9151\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.2182 - accuracy: 0.9310 - val_loss: 0.2731 - val_accuracy: 0.9143\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2858 - accuracy: 0.9104\n",
            "K-FOLD 3\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.2127 - accuracy: 0.9317 - val_loss: 0.2714 - val_accuracy: 0.9161\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.2083 - accuracy: 0.9344 - val_loss: 0.2750 - val_accuracy: 0.9169\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.2016 - accuracy: 0.9365 - val_loss: 0.2731 - val_accuracy: 0.9169\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.2004 - accuracy: 0.9380 - val_loss: 0.2825 - val_accuracy: 0.9146\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1990 - accuracy: 0.9368 - val_loss: 0.2723 - val_accuracy: 0.9154\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 39s 104ms/step - loss: 0.1934 - accuracy: 0.9386 - val_loss: 0.2767 - val_accuracy: 0.9165\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1880 - accuracy: 0.9409 - val_loss: 0.2764 - val_accuracy: 0.9187\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.1836 - accuracy: 0.9423 - val_loss: 0.2776 - val_accuracy: 0.9172\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1823 - accuracy: 0.9435 - val_loss: 0.2829 - val_accuracy: 0.9178\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.1788 - accuracy: 0.9426 - val_loss: 0.2831 - val_accuracy: 0.9181\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2952 - accuracy: 0.9139\n",
            "K-FOLD 4\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.1764 - accuracy: 0.9441 - val_loss: 0.2829 - val_accuracy: 0.9177\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1731 - accuracy: 0.9462 - val_loss: 0.2867 - val_accuracy: 0.9189\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1694 - accuracy: 0.9473 - val_loss: 0.2919 - val_accuracy: 0.9169\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1685 - accuracy: 0.9471 - val_loss: 0.2846 - val_accuracy: 0.9176\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1649 - accuracy: 0.9489 - val_loss: 0.3074 - val_accuracy: 0.9144\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 39s 104ms/step - loss: 0.1624 - accuracy: 0.9494 - val_loss: 0.2828 - val_accuracy: 0.9188\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1593 - accuracy: 0.9498 - val_loss: 0.2865 - val_accuracy: 0.9174\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.1581 - accuracy: 0.9501 - val_loss: 0.3029 - val_accuracy: 0.9170\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 36s 96ms/step - loss: 0.1564 - accuracy: 0.9505 - val_loss: 0.3024 - val_accuracy: 0.9172\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1541 - accuracy: 0.9529 - val_loss: 0.2973 - val_accuracy: 0.9175\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3067 - accuracy: 0.9148\n",
            "K-FOLD 5\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.1524 - accuracy: 0.9519 - val_loss: 0.3011 - val_accuracy: 0.9178\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.1483 - accuracy: 0.9539 - val_loss: 0.3013 - val_accuracy: 0.9171\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.1455 - accuracy: 0.9557 - val_loss: 0.3043 - val_accuracy: 0.9192\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1453 - accuracy: 0.9550 - val_loss: 0.2985 - val_accuracy: 0.9188\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1393 - accuracy: 0.9573 - val_loss: 0.3096 - val_accuracy: 0.9182\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1407 - accuracy: 0.9569 - val_loss: 0.3107 - val_accuracy: 0.9165\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1376 - accuracy: 0.9573 - val_loss: 0.3157 - val_accuracy: 0.9179\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1367 - accuracy: 0.9577 - val_loss: 0.3122 - val_accuracy: 0.9167\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 36s 95ms/step - loss: 0.1354 - accuracy: 0.9593 - val_loss: 0.3224 - val_accuracy: 0.9158\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 36s 97ms/step - loss: 0.1355 - accuracy: 0.9579 - val_loss: 0.3304 - val_accuracy: 0.9151\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3525 - accuracy: 0.9138\n"
          ]
        }
      ],
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True) #declaring number of folds. Shuffle=True means datset is shuffled after every split\n",
        "n=1\n",
        "accuracy_list = []             #list to hold the 5 accuracy scores from the 5 folds\n",
        "loss_list=[]                   #list to hold the 5 loss scores from the 5 folds\n",
        "for train, test in kfold.split(train_images, train_labels):\n",
        "  print(f\"K-FOLD {n}\")\n",
        "  model.fit(train_images, train_labels, batch_size=BATCH_SIZE,epochs=N_EPOCHS, validation_split=VALIDATION_SPLIT,verbose=VERBOSE)  #fitting the model to the data\n",
        "  loss, accuracy = model.evaluate(test_images, test_labels)  # evaluate loss and accuracy scores and append them to respective lists\n",
        "  accuracy_list.append(accuracy)\n",
        "  loss_list.append(loss)\n",
        "  n=n+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFMiFtDCpjMG"
      },
      "source": [
        "Evaluate your model in cross-validation. Calculate and print the loss and accuracy scores in each fold. Print the average cross-validation accuracy and loss your network achieved (in all folds). **(15 marks)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WnCeV6qP6xmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff651ede-beb7-4486-e750-fd8b17fdf6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the accuracy scores for each k-fold are:  [0.9053999781608582, 0.9103999733924866, 0.9139000177383423, 0.9147999882698059, 0.9138000011444092]\n",
            "the loss scores for each k-fold are:  [0.2879372239112854, 0.2857828736305237, 0.2952173948287964, 0.30669838190078735, 0.3525087833404541]\n",
            "the average accuracy across all folds is: 0.912\n",
            "the average loss across all folds is: 0.306\n"
          ]
        }
      ],
      "source": [
        "print('the accuracy scores for each k-fold are: ', accuracy_list)  #display accuracy score for each k-fold\n",
        "print('the loss scores for each k-fold are: ',loss_list)           #display loss score for each k-fold\n",
        "avg_accuracy= sum(accuracy_list)/len(accuracy_list)  #mean/avg accuracy\n",
        "avg_loss= sum(loss_list)/len(loss_list)             #mean/avg loss\n",
        "\n",
        "print(f\"the average accuracy across all folds is: {avg_accuracy:.3f}\")\n",
        "print(f\"the average loss across all folds is: {avg_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GvX1moIqqm0"
      },
      "source": [
        "*your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S48e3kq_qCCi"
      },
      "source": [
        "Plot the final results (accuracy/loss) on the test set in each fold. **(10 marks)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DLLIrvy2psKZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "05bf0953-5888-4195-94b7-2eb63ebf988a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(accuracy_list,loss_list,'r-')  #accuracy list as x and loss list as y (line)\n",
        "plt.plot(accuracy_list,loss_list,'ro')  #accuracy list as x and loss list as y (points)\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Accuracy vs Loss')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImI7busBrCie"
      },
      "source": [
        "Additional questions:\n",
        "\n",
        "\n",
        "*   Describe whether you found any differences in the networkâ€™s accuracy when applying regularisation compared to not applying it. If there were differences, which regularisation did you use? If no differences were found, what could be the reason? **(10 marks)**\n",
        "\n",
        "Ans: Yes, initially I did not apply a regularisation technique and my accuracy hit a plateau when it got to 0.90. I then increased the number of neurons in the dense layer and applied an L1 regulariser. This increased my accuracy to 0.91, and reduced my loss to 0.32, from 0.41.\n",
        "\n",
        "*   Write your conclusions about the results achieved with your model on the fashion MNIST dataset and ideas to improve these results/performance further. **(10 marks)**\n",
        "\n",
        "Ans: I think my model performed well. Having a convolutional layer meant I did not need to train it for as many epochs as a multi-layer perceptron. Regularisers are very much needed to prevent overfitting, as stated above. I experimented with different ones and found L1 regulariser gave me the best results. Having an incessantly large number of neurons increased my training time without increasing my accuracy. These are my conclusions.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcSc_1JiqRA3"
      },
      "source": [
        "Additional remarks:\n",
        "\n",
        "*   Code outline appropriately commented. **(10 marks)**\n",
        "*   Code running without errors. **(10 marks)**\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3e7af04d29b7c7f09156ce72bf463dad5c8b45a218773abf1ffb50277174388"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}